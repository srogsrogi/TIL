# AI



## Warm-up





## 머신러닝의 기본 개념과 학습 원리

### 머신러닝이란?

- 컴퓨터가 데이터로부터 패턴을 학습하는 기술

- **경험적**으로 얻은 데이터 분포를 기반으로, 새로운 입력의 출력값을 **확률적**으로 추정



### 머신러닝의 종류

* 지도학습(Supervised Learning)

  * 입력 데이터(X)와 그에 대응하는 **라벨(y)을 함께 제공**하여 학습하는 방법
  * 대표 Task : **분류**(Classification) | **회귀**(Regression)

* 비지도학습(Unsupervised Learning)

  * **라벨이 없는 상태**에서 데이터의 패턴이나 구조를 스스로 학습하는 방법
  * 대표 Task : **클러스터링**, **PCA**(차원 축소)

* 강화학습(Reinforcement Learning)

  * 주어진 **환경** 속에서 **행동**에 따른 **보상**을 바탕으로 **누적 보상을 극대화**하며 학습하는 방법
  * 오늘은 자세히 다루지 않을 것

  

### 모델의 학습 과정

   * 목표 : 2차 함수인 손실함수에서 극소점을 찾는 최적화 문제

       * **최소제곱법(OLS)** : 왜 손실함수는 오차에 대한 2차함수인가? **손실함수의 정의**
            * 손실은 개별 데이터에 대한 예측값과 실제값의 차이**(오차)의 평균**으로 정의할 수 있음
            * 그런데, 오차는 양수일 수도 있고 음수일 수도 있기 때문에 단순합하면 손실이 상쇄됨
            * 따라서 오차를 모두 양수로 처리한 후 누적합해야 함
                 * 방법 1 : 오차의 **절대값**을 누적합하는 것
                 * 방법 2 : 오차를 **제곱**하여 누적합하는 것
                 * 일반적으로, 예측의 안정성을 위해 **큰 오차에는 더 큰 페널티를 부여하는 제곱 방식**을 사용
                 * 손실함수가 이차함수 형태일 경우 뒤이어 나올 경사하강법을 적용하기도 좋음

       - **경사하강법(GD)** : 어떻게 오차를 줄여나갈 것인가? **손실함수의 최적화 방법**
         - 원래 손실함수의 형태를 알고 있으면, 미분해서 기울기가 0인 지점을 구하면 끝이지만..
         - 우리는 손실함수의 형태를 모르는 상태에서 극소화하고, 원함수의 파라미터를 추정해야 함
         - 일단 원함수에 아무 파라미터나 찍어서 대입해보고, 손실함수를 미분해서 기울기를 계산
         - 기울기가 0인 점이 극소점일테니까, 기울기의 부호를 보고 0에 가까워지는 방향으로 파라미터를 업데이트하기를 반복
         - 기울기가 0에 가까워질 때까지 충분히 이동하여 손실함수가 가장 작은 지점이, 모델이 추정한 최적의 파라미터가 됨
       - **확률적 경사하강법(SGD)** : 경사하강법의 효율적 변형
         - 전통적 경사하강법은 가중치를 한 번 업데이트할 때마다 전체 데이터에 대한 오차를 전부 계산
         - SGD는 **일부 샘플(mini-batch)만 사용**하여 기울기를 근사하여 추정하는 방법
         - SGD의 장점
           - 1회 업데이트하는 데에 필요한 연산이 줄어들어 **빠른 학습 가능**
           - 무작위로 발생하는 noise가 비선형함수의 **국소해(local minima)에 빠질 위험을 줄여줌**

---

## 머신러닝의 과정

### 데이터 준비 및 가공 (Data Preparation)

* 특성 공학(Feature Engineering)
  * 모델이 학습하기 좋은 형태로 입력 데이터(X)를 변형하는 것
  * 특성 공학의 주요 구성 요소
    * 특성 선택 : 불필요하거나 다른 변수와 상관관계가 높은 변수를 제거
    * 특성 변환 : 정규화, 표준화, 로그 변환 등 스케일이나 분포를 변경
    * 특성 인코딩 : 범주형 변수를 수치형으로 변환
    * 파생 변수 생성 : 기존 특성을 조합해 새 특성 생성
    * 차원 축소 : 고차원 데이터를 압축하여 본질적인 정보만 유지

#### 특성 공학의 주요 요소 중 정규화, 표준화, 인코딩은 조금 더 자세히 설명

* 정규화(Normalization)

  * 서로 다른 스케일을 가진 변수들을 **일정한 범위**로 맞춰주는 과정
  * 스케일이 큰 변수의 영향력이 상대적으로 커지는 현상을 방지하기 위해 수행
  * 범위를 0~1로 맞춰 주는 **Min-Max Scaling**이 자주 활용됨

* 표준화(Standardization)

  * **분포**의 중심(평균)과 폭(분산)을 맞춰주는 과정
  * 분포의 차이에 따라 변수별 영향력이 왜곡되는 현상을 방지하기 위해 수행
  * 평균 0, 표준편차 1로 분포를 통일해주는 **Standardization(Z-score Scaling)**이 자주 활용됨

* 인코딩(Encoding)

  * Label Encoding

    * 각 범주에 정수 번호를 부여하는 방식
    * 사과 : 1, 배 : 2, 바나나 : 3
    * 부여된 정수의 크기(순서)가 학습에 관여할 수 있음

  * One-Hot Encoding

    * 범주 수만큼 컬럼을 만들어 이진 표현(하나의 컬럼만 1로 표현)
    * 사과 : (1,0,0), 배 : (0,1,0), 바나나 : (0,0,1)
    * 각 범주에 대한 정보가 독립적이기 때문에 정수의 연속성이 학습에 활용되지 않음

  * 그 외에 Target Encoding, Binary Encoding 등 다양한 인코딩 방법이 있으나, One-Hot Encoding을 가장 많이 활용하게 될 것

    

### 모델의 신뢰도 확보 (Model Validation)

* 데이터 분할(Hold-out)

     * 데이터셋을 **학습용과 평가용으로 나누어** 일반화 성능을 검증하는 방법
     * 학습한 데이터를 평가에도 활용할 경우 가진 데이터셋에 과적합(overfit)되어 새로운 데이터에 대한 추론 성능이 떨어질 수 있음
     * 따라서 훈련시에는 평가용 데이터셋을 모델에 입력하지 않고,
     * 훈련 데이터에 대한 평가 지표와 평가 데이터에 대한 평가 지표를 비교하여 과적합의 신호로 활용

* 교차 검증(Cross Validation)

     * 데이터를 여러 번 나누어 훈련과 검증을 반복하는 방법
     * 홀드아웃의 한계점인 무작위성에 의한 편차를 줄이고 평균적인 성능을 정확히 추정
     * 데이터를 K개로 나누어 순서대로 검증하는 **K-Fold** 교차 검증이 대표적이며, 고도화된 다른 방법들도 있음

     

### 모델 성능 평가(Model Evaluation)

- 혼동 행렬(Confusion Matrix)

  | **실제 / 예측**     | **Positive (예측)**     | **Negative (예측)**     |
  | ------------------- | ----------------------- | ----------------------- |
  | **Positive (실제)** | **TP (True Positive)**  | **FN (False Negative)** |
  | **Negative (실제)** | **FP (False Positive)** | **TN (True Negative)**  |

- ML의 주요 평가지표

  - 분류 모델의 주요 평가 지표
    - Accuracy : 전체 중 정답 비율. `(TP + TN) / (TP + TN + FP + FN)`
    - Precision : 예측이 Positive인 것 중 실제로 Positive인 비율. `TP / (TP + FP)`
    - Recall : 실제 Positive인 것 중 예측이 Positive인 비율. `TP / (TP + FN)`
    - F1-score
      - Precision과 Recall의 조화평균
      - Precision과 Recall 사이에는 Trade-off가 있음
      - F1-score는 어느 한 쪽 지표에 치우치지 않은 종합적인 성능을 보여줌
    - ROC-AUC
      - ROC curve : X축을 FPR(`FP / (FP + TN)`), Y축을 Recall로 하는 그래프
      - AUC : ROC curve 아래 쪽의 면적
      - 임의의 샘플에 대하여 모델이 Negative보다 Positive에 더 높은 점수를 줄 확률
      - 0~1 사이의 값을 가지며, 1에 가까울 수록 모델의 성능이 좋음을 나타냄
      - 불균형한 데이터셋에서도 모델의 성능을 정확하게 평가하는 지표
  - 회귀 모델의 주요 평가 지표
    - (adjusted) R^2 : **결정계수**. 모델이 실제 데이터를 얼마나 잘 설명하는지를 나타내는 지표
    - MSE / RMSE / MSLE / RMSLE : **오차 제곱의 평균**(MSE)과 그 변형(Root, Log 변환) 지표
    - MAE  : 오차 절대값의 평균
    - MAPE : 실제값 대비 예측값의 오차를 **백분율(%) 단위로 평균**한 값



### 규제(Regularization)

- 과적합을 방지하기 위해 학습 도중 손실함수에 페널티를 추가하는 방법

- 데이터에서 진짜 의미 있는 신호(특성)에 더 집중하도록 만들고 원함수의 복잡성을 제한함

- λ(lambda) 값을 통해 규제의 정도를 조절할 수 있음

- 대표적인 규제 방식

  - L1 규제(Lasso)

    - 일부 변수에 대한 가중치를 0으로 만듦
    - 모델이 수행하는, 자동화된 특성 선택으로 볼 수 있음

  - L2 규제(Ridge)

    - 변수들의 가중치 크기를 줄여 영향력이 작은 변수의 효과를 희석시키는 방법
    - 모든 변수가 살아남지만, 가중치가 균형 있게 줄어듦

  - Elastic Net

    - L1(변수 선택 효과) + L2(안정성 부여) 규제의 장점을 결합한 형태
    - L1규제와 L2규제의 비율을 조정하여 복합적으로 활용
    - 실무에서 자주 쓰임

    

### 하이퍼파라미터 튜닝

- 하이퍼파라미터란?
  - 사람이 모델의 학습 과정을 제어하는 외부 설정값
  - 학습률, epoch 수, 규제 강도, k-Fold CV의 k값, 모델별 설정값 등
  - 모델이 학습시 추정하는 파라미터와 혼동하지 말 것!

- 하이퍼파라미터 튜닝
  - 모델이 과적합되지 않으면서 최대한의 성능을 낼 수 있는 **하이퍼파라미터 조합을 탐색**하는 것

- 대표적인 하이퍼파라미터 튜닝 방식

  - Grid Search
    - 모든 하이퍼파라미터 조합을 전부 탐색하는 방식
    - 데이터와 파라미터 수가 적을 때는 활용 가능하나, 조합이 많아 거의 쓰이지 않음
  - Randomized Search
    - 가능한 조합 중 일부를 무작위로 선택하여 탐색
    - 확률분포에 기반하여 균형 있는 랜덤 샘플링 수행
    - Grid Search에 비해 훨씬 적은 탐색 횟수로도 충분히 좋은 조합 탐색 가능

  - Bayesian Optimization
    - 임의로 선택된 몇 개의 파라미터 조합으로 초기 데이터를 생성하고
    - 그 데이터를 기반으로 파라미터 조합에 대한 모델을 학습 및 추론해나가는 방법
    - 이전 탐색 결과를 바탕으로 성능이 좋아질 가능성이 큰 조합을 다음 탐색 위치로 선택하며 탐색해나감

  - Optuna
    - Bayesian Optimization을 기반으로 한 하이퍼파라미터 튜닝 라이브러리
    - 자동 pruning 등 기능 최적화가 이루어져 있어 실무에서 자주 사용

---

## 전통 머신러닝 핵심 알고리즘

### 지도학습

#### 분류 알고리즘

* KNN
* 로지스틱 회귀

* SVM

* Decision Tree

     

#### 회귀 알고리즘

- 선형 회귀
- Ridge / Lasso / ElasticNet 회귀
- SVR
- Decision Tree Regressor



#### 앙상블 기법

* 여러 모델을 결합하여 더 성능이 좋은 하나의 모델을 만드는 방법
* 분류와 회귀 등 여러 Task에 적용할 수 있음
* 배깅(Bagging)
  * Random Forest
* 부스팅(Boosting)
  * XGBoost 등



### 비지도학습

#### 클러스터링

- K-Means

- DBSCAN

#### PCA



  4부: 딥러닝의 서막 (15분)

   * 4-1. 퍼셉트론의 한계와 극복
       * XOR 게이트 문제와 단층 퍼셉트론
       * 다층 퍼셉트론으로의 진화
   * 4-2. 딥러닝은 어떻게 학습하는가?
       * 활성화 함수 (Sigmoid, Softmax, ReLU)
       * 역전파 (Backpropagation)
       * 딥러닝을 위한 규제: 드롭아웃 (Dropout)

  5부: 분야별 핵심 딥러닝 아키텍처와 최신 트렌드 (20분)

   * 5-1. 이미지 처리를 위한 CNN (Convolutional Neural Network)
   * 5-2. 순차 데이터(시계열, 텍스트)를 위한 RNN & LSTM
   * 5-3. 현대 자연어처리(NLP)의 게임 체인저
       * 어텐션(Attention)과 트랜스포머(Transformer)
   * 5-4. 딥러닝의 활용
       * 추천 시스템
       * 사전학습 및 파인튜닝