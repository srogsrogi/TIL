# AI 3일차 - NLP



## Keywords

- NLP
- LLM
- Prompt Engineering
- Prompt Evaluation



## 질문 / 답변

- Q1. 요즘 모델들은 CoT와 비슷한 알고리즘이 내장돼있어서 CoT 프롬프팅을 적용했을 때 성능에 유의미한 변화가 없거나 오히려 소폭 하락할 수 있다는 얘기도 있던데 실제로 그런가요?

  - 23~24년 Google, OpenAI 연구들(GPT-4급 모델들) 기준으로..
    - 13B급 이하 모델들에서는 CoT 프롬프팅이 여전히 유효한 케이스가 있고
    - 70B급 이상 모델들에서는 효과가 없가나 소폭 하락하는게 맞음
    - o계열 추론 모델들에서만 나타나는 현상이 아니라 기본 모델들도 마찬가지

  - GPT-5는 학습 단계부터 CoT reasoning을 통합하여 그런 경향이 더 심함
    - 명시적 CoT 프롬프팅 적용시 유의미한 성능 저하가 나타남

  - 원인은 `과도한 reasoning`과 `off-track hallucination`
    - off-track hallucination : 논리적으로 생각은 하지만 방향 자체가 틀린 경우



- Q2. 소규모 프로젝트에서 프롬프트 테스트를 해봤을 때, output의 quality에 대한 정량적인 평가지표를 설정하기가 어려웠는데, 프롬프트의 quality에 대한 평가는 어떻게 해볼 수 있을까요?
  - 니가 경험한 대로, 사람이 직접 하자니 비용도 너무 빡세고.. 점점 생성형 AI를 활용하는 추세
  - **AI as a Judge**라고 불리는데.. 활발히 연구중인 분야
  - 세부적인 방법론은 아주 다양함
    - 평가지표 자체도 LLM이 만들게 할 수도 있고
    - 평가지표는 사람이 만들고 그에 따라 LLM이 평가하도록 할 수도 있고
    - 평가자인 LLM을 다수로 늘려 투표시키는 방식이나
    - 두 모델이 토론하고 제 3의 모델이 그걸 평가하는 방법이라든지.. 무궁무진함
  - 뭐가 무조건 낫다고 하긴 좀 어려움. 이거야말로 도메인/목표/가용 리소스에 따라 달라서..
  - GPT-5는 judge 기능도 내장돼서 self-verification함
  - 도입할 때 주의할 점은
    - 자기참조로 인한 bias 강화
    - 평가 모델의 bias가 피평가자 모델에 전이
    - off-topic hallucination 등이 있음

