# AI 3일차 - NLP

- 강사 : 연세대학교 여진영 교수
- 계속 강사 바뀌면서 특강 식으로, 압축적으로 진행되는게 좀 많이 별로긴 한데..
- 이해할 수 있는 만큼만 이해하고 질문할 거 하고.. 강의 자체에 매몰될 필요 없이 주도적으로 공부하는게 나을 듯



## Keywords

- NLP
- LLM
- Prompt Engineering
- Prompt Evaluation



## 질문 / 답변

- Q1. 요즘 모델들은 CoT와 비슷한 알고리즘이 내장돼있어서 CoT 프롬프팅을 적용했을 때 성능에 유의미한 변화가 없거나 오히려 소폭 하락할 수 있다는 얘기도 있던데 실제로 그래?

  - 23~24년 Google, OpenAI 연구들(GPT-4급 모델들) 기준으로..
    - 13B급 이하 모델들에서는 CoT 프롬프팅이 여전히 유효한 케이스가 있고
    - 70B급 이상 모델들에서는 효과가 없가나 소폭 하락하는게 맞음
    - o계열 추론 모델들에서만 나타나는 현상이 아니라 기본 모델들도 마찬가지

  - GPT-5는 학습 단계부터 CoT reasoning을 통합하여 그런 경향이 더 심함
    - 명시적 CoT 프롬프팅 적용시 유의미한 성능 저하가 나타남

  - 원인은 `과도한 reasoning`과 `off-track hallucination`
    - off-track hallucination : 논리적으로 생각은 하지만 방향 자체가 틀린 경우



- Q2. 소규모 프로젝트에서 프롬프트 테스트를 해봤을 때, output의 quality에 대한 정량적인 평가지표를 설정하기가 어려웠는데, 보통 프롬프트의 quality에 대한 평가는 어떻게 함?
  - 니가 경험한 대로, 사람이 직접 하자니 비용도 너무 빡세고.. 점점 생성형 AI를 활용하는 추세
  - **AI as a Judge**라고 불리는데.. 활발히 연구중인 분야
  - 세부적인 방법론은 아주 다양함
    - 평가지표 자체도 LLM이 만들게 할 수도 있고
    - 평가지표는 사람이 만들고 그에 따라 LLM이 평가하도록 할 수도 있고
    - 평가자인 LLM을 다수로 늘려 투표시키는 방식이나
    - 두 모델이 토론하고 제 3의 모델이 그걸 평가하는 방법이라든지.. 무궁무진함
  - 뭐가 무조건 낫다고 하긴 좀 어려움. 이거야말로 도메인/목표/가용 리소스에 따라 달라서..
  - GPT-5는 judge 기능도 내장돼서 self-verification함
  - 도입할 때 주의할 점은
    - 자기참조로 인한 bias 강화
    - 평가 모델의 bias가 피평가자 모델에 전이
    - off-topic hallucination 등이 있음



- Q3. 조사를 불용어로 처리하면 “철수가 영희를 좋아한다.”랑 “철수를 영희가 좋아한다.”랑 구분을 못 하는데 의미를 제대로 학습할 수가 있나? 한국어는 조사가 문장성분을 결정하는데 빼도 되는 이유를 모르겠네
    - 데이터가 많을 수록, 문맥 기반으로 학습이 이루어질수록(주로 transformer 기반 모델) 조사는 그렇게 중요하지 않을 때가 많음.
    - 물론 조사가 중요한 경우에는 조사를 불용어처리하지 않고 별도 토큰으로 분리해내거나, 조사를 제거한 버전과 원문을 병행학습하는 등의 방법으로 조사의 의미를 살려 두는 모델을 만들면 됨. 사전학습모델도 조사를 함께 학습해놓은 것들도 있음.
    - 불용어는 도메인에 따라 달라지는 것. 상황에 맞게 커스터마이징해서 쓰면 된다.



- Q4-1. 워드임베딩 모델에서 반의어간 유사도 값은 -1에 가까운 음수값을 가질 거 아냐. 근데 반의어가 문맥에 따라 유의어처럼 쓰일 수도 있는 거 아냐? 가령 Lady와 Gentleman은 반의어처럼 보이지만 Ladies and Gentlemen~ 하면 이건 그냥 둘다 사람들의 의미로 유사하게 쓰인 거잖아. 그럼 모델이 저 문장을 똑바로 해석할 수가 있을까?
    - 일단 음수값을 갖는 건, 각 단어가 가지고 있는 수많은 벡터 중 하나에 대해서만 그럴 거임. lady와 gentleman 사이에 하나의 유사도값이 있는게 아니라, 걔네가 수많은 벡터(단어의 성질에 대응되지만, 그 성질이 정확히 뭔지는 인간이 알 수 없음)를 가지고 있고 각각의 벡터에 대해 유사도 값을 가지고 있는 거임.
    - 그럼 종(species)과 관련된 벡터가 있다면, lady와 gentleman은 되게 가까이에 위치하고 양수의 유사도 값을 갖겠지. 이런 수많은 벡터들이 있고 모델은 그것들을 모두 뭉뚱그려서 가지고 있는 거임.
- Q4-2. 그럼 그냥 다차원 벡터만 가지고 있으면 모델이 알아서 문맥에 따라 유의어로 보기도 하고 반의어로 보기도 한다는 거야?
    - 고정된 워드 임베딩(Word2Vec 등)에서는 각 단어마다 고정된 하나의 벡터(주로 100차원이나 300차원)만을 가지기 때문에 반의어를 학습하기가 어려움. lady와 gentleman은 일반적으로 가까운 위치에 있게 되고 그 위치는 문맥에 따라 변하지 않음.
    - 이걸 보완하기 위해 문맥 기반 워드 임베딩(BERT 등)이 등장했는데, 얘네는 문맥에 따라 벡터의 위치 자체가 동적으로 변하기 때문에 문맥에 따라 반의어가 되는 경우도 잘 학습할 수 있음
- Q4-3. 그럼 고정된 워드임베딩에서 코사인 유사도가 음수가 나오는 애들은 뭐임? man과 woman도 유사도가 높아서 양수로 나오는데 어떻게 음수가 되지?
    - man과 woman은 사람이라는 범주 내에서 반대인 성질이 있을 뿐이니까 양의 유사도를 갖는 거고, 가령 hot과 cold, up과 down처럼 애초에 완전 반댓말인 경우는 음의 유사도를 가질 수 있음. 이런 애들은 고정된 워드 임베딩만으로도 충분히 반의어 관계가 잘 학습됨



- Q5-1. word embedding 모델도 pre-trained model에 전이학습시켜서 특정 분야에 특화시킬 수 있을 것 같은데?
    - 물론 가능. 특정 도메인과 관련된 텍스트데이터를 추가로 주고 학습시킬 수 있음.
- Q5-2. 근데 전에 했던 딥러닝 모델은 출력층을 분류 클래스 수에 맞게 맞춰준다든지, 목적에 따라 활성화함수를 바꿔준다든지 하는 특수한 목적이 있었는데, 워드임베딩은 추가학습 해봤자 그냥 기존 모델이 학습한 방식으로 데이터만 좀 추가해서 학습하는 것뿐 아닌가? 뭐가 많이 바뀜?
    - 맞긴 해. 딥러닝모델에서의 전이학습이나 fine tuning과는 느낌이 좀 다르긴 함.
    - 딥러닝 모델에서의 전이학습은 커스텀 레이어를 통해서 출력층 구조를 바꿔주는 등의 작업이 있었는데, 워드임베딩의 경우는 그게 없고 그냥 특정 도메인으로 모델을 그대로 갖다 쓰는거 자체를 전이학습이라고 함.
    - 미세조정 개념은.. 가령 사전학습모델은 heart를 가슴, 마음 같은 일반적인 의미로 잔뜩 학습해놨을 거 아냐. 거기다가 의학 관련 텍스트 데이터를 잔뜩 밀어넣고 학습시켜서 모델이 heart를 심장의 의미로 이해하도록 벡터값을 조정해주는 거임. 딥러닝모델에서 실제로 가중치를 조정해줬던 거랑 같은 거지.
- Q5-3. 그럼 일반적으로 데이터의 양이 많을수록 학습 성능이 좋은 것과는 다르게, 이런 미세 조정의 과정에서는 데이터를 많이 준다고 해서 좋은게 아니네? 데이터를 너무 많이 줘버리면 원래 일반적인 맥락에서의 의미를 잃어버릴 거 아냐.
    - ㅇㅇ. 도메인이나 상황에 따라 그 균형을 조절하는게 중요함.
- Q5-4. 그니까 미세조정은 사전학습모델에 새로운 데이터를 밀어넣어서 가중치를 조정한다는 점에서 딥러닝모델에서나 워드임베딩에서나 개념적 차이가 별로 없고, 전이학습은 워드임베딩에서는 모델에 별다른 변화 없이 갖다 쓰는 거 자체가 전이학습이지만, 딥러닝모델에서는 출력층을 추가해서 모델 구조를 변화시킨다는 점만 다른 거네.
    - 그렇게 이해하면 맞는 듯. 결국 근본적으로는 별 다를 거 없음.



- Q6. 은(silver)가 중요한 의미를 가지는 텍스트에서는 그걸 불용어처리하면 안 될 거 아냐. 이런 식으로 불용어와 동음이의어인 일반 단어들을 불용어처리되지 않게 하는 방법이 있을까?
    - konlpy의 형태소기반분석을 통해 ‘은’이 josa로 분류된 경우만 불용어처리하면 됨.
    - 정규표현식이나 딥러닝 모델의 문맥 분석 기능을 사용할 수도 있음



- Q7-1. 토크나이징할 때 num_words의 vocab size가 data에 등장하는 단어의 총 개수보다 적을거 아냐. 알아서 많이 등장한 단어부터 사전에 넣는 거야?
    - ㅇㅇ.
- Q7-2. 그럼 등장 횟수가 같은 단어들끼리는 어떡해?
    - 그냥 앞에서부터 사전에 넣기 때문에 앞쪽 인덱스에 있는 단어들부터 선택됨.
- Q7-3. 만약에 총 단어 개수보다 vocab size가 더 크면 어떻게 처리돼?
    - 그냥 모든 단어가 다 사전에 들어가고, num_words 인자는 안 준 거랑 똑같음.
- Q7-4. 그건 좀 불공평한데. n회 이상 등장한 단어들만 사전에 넣는 방법이 낫지 않나? 그런 방법은 없어?
    - 직접적으로 그런 메소드나 인자를 제공하고 있지는 않은데, 니가 하면 할 수는 있음.



- Q8. nlp할 때 패딩의 매개변수 truncating, padding 자리에 pre나 post를 넣잖아. 근데 앞이나 뒤 말고 가운데를 하는게 낫지 않나? 사람이 글을 쓴다고 하면 보통 두괄식이나 미괄식으로 쓰지, 중요한 정보가 문장의 가운데에 들어가는 경우가 훨씬 적을텐데.
    - 경우에 따라서는 그럴 수도 있는데, 문제는 padding이나 truncating을 가운데서 하려면 시퀀스의 길이에 따라 앞뒤에 패딩할 패딩문자의 수를 동적으로 결정해야 하기 때문에 연산량이 많아짐. 학습/추론의 과정 모두 무거워질 수 있기 때문에 잘 쓰지는 않음.
    - 또, 패딩의 위치가 매 문장마다 달라지고 처리 순서도 일정하지 않아지기 때문에 오히려 모델의 학습 성능을 떨어뜨릴 가능성이 있음.
    - 그럼에도 불구하고 데이터의 특성에 따라 그렇게 하는게 나은 경우도 있겠지. 일단 인자로 제공하고 있지는 않고, 니가 만들어서 써야 됨.
    - 순차적 모델(RNN, LSTM, GRU)에서는 패딩의 위치가 학습 성능에 유의미한 영향을 미치지만, transformer계열의 모델은 병렬 연산을 하기 때문에 패딩을 어디다 하든 별반 차이가 없어서 그쪽에서는 굳이 가운데 패딩을 할 일은 없을 듯.



- Q9-1. Seq2Seq모델은 한 문장을 추론하기 위한 거고, 그 안에 있는 디코더의 추론 모델이 단어의 개수만큼 반복되면서 한 문장이 번역되는 거지?
    - ㅇㅇ.
- Q9-2. 그럼 모델의 input 개수만큼 output이 생기고 그게 각각 토큰이 되는 거 아닌가? 실제로 번역할 때는 번역하려는 문장의 단어 개수와 번역된 문장의 단어 개수가 다를 수 있잖아.
    - 인코더 모델의 input과 디코더 모델의 input은 개수가 다를 수 있음. 디코더 모델에서의 input과 output 개수는 같겠지.
- Q9-3. 그럼 인코더 모델의 input과 output 개수는 다를 수 있고, 인코더 모델의 output과 디코더 모델의 input, output 개수는 모두 같은 거야?
    - 인코더 모델의 input과 output 개수가 다를 수 있는 것도 맞고, 디코더 모델의 input, output 개수(출력 토큰 개수)가 같은 것도 맞음
    - 근데 인코더의 output과 디코더의 input도 역시 다를 수 있음.
    - 디코더는 인코더의 output을 그대로 받아오는게 아니라, 인코더가 만들어낸 정보를 바탕으로 독립적으로 작동함.
    - 디코더는 input의 개수와 상관 없이, <eos>가 나올 때까지 계속 돌면서 문장을 만들어냄.



- Q10-1. Seq2Seq는 한 문장만 번역한다며. 그럼 여러 문장이 들어 있는 코퍼스 전체를 번역할 때는 Seq2Seq모델이 문장 개수만큼 반복해서 돌고, 그 안에서 또 추론모델이 단어 개수만큼 반복해서 도는 이중반복문의 형태가 되는 거야?
    - 맞음.
- Q10-2. 그럼 다음 문장으로 문맥을 전달하기 위해 eos를 만날 때의 h, c state를 다음 문장의 첫 단어에 전달해서 번역을 이어가는 건가?
    - 그게 가능하긴 한데.. 문맥이 길어질수록 정보 손실이 심해져서 성능이 떨어짐. 그걸 해결하기 위해 Attention 메커니즘이나 transformer가 나온 거임
    - Attention은 각 타임스텝의 h state에 가중치를 매겨서 단일 h,c state뿐 아니라 입력 전체에 대한 정보를 통해 모델이 각 타임스텝에서 중요한 정보에 집중하도록 해주는 방식임.
    - Attention을 쓰든 안 쓰든, seq2seq는 개별 토큰을 예측해야 다음 토큰을 예측하는 직렬 방식으로 작동하니까 GPU 활용이 잘 안 됨. transformer는 병렬 처리가 가능해서 일반적으로 seq2seq보다 훨씬 빠르고, 긴 코퍼스에 대한 추론 성능도 더 좋은 편.
    - 그렇다고 seq2seq가 쓸모가 없는 건 아니고.. 비교적 문장이 짧고 단순하거나, 데이터셋이 적거나 한 상황에서는 더 좋을 수도 있음. 모델 크기도 더 작아서 가볍기도 함.
- Q10-3. Attention은 seq2seq모델을 쓸 때 항상 쓰는 기법인가?
    - ㅇㅇ. 여러 문장을 번역해야 하거나, 한 문장이더라도 문장이 길어지고 구조가 복잡해질수록 성능이 떨어지는 seq2seq의 단점을 많이 보완해줘서 실질적으로 거의 무조건 함께하는 메커니즘임.



- Q11. Attention이 토큰의 중요도에 따라 가중치를 부여해준다면, 굳이 불용어를 없애지 않아도 되는 거 아닌가? 물론 연산량은 좀 늘어나겠지만 그게 더 성능이 좋을 수도 있겠는데
    - 실제로 그렇게 하고 있음. 근데 진짜 쓸데없는 단어들은 오히려 학습을 방해할 수도 있고, 전체적인 연산량이 많이 늘어나기 때문에 아예 불용어 처리를 안 하는 게 능사는 아님.
    - BERT나 GPT 등은 보통 불용어 처리 없이 원문 그대로 처리함.
    - 상황에 따라 불용어를 아예 없애거나, 일부만 남기거나 하는 식으로 설계하면 됨. 딱 정해져있는 건 아니고, 이전의 모델들에 비해 불용어 처리의 중요도가 낮아진 건 맞음.



- Q12-1. OutputParser 왜 쓰는거야? 그냥 프롬프팅 메시지에 출력형식 지정하는게 연산량이 더 적지 않나?
    - OutputParser가 사용하는 리소스가 LLM에 비해 매우 적기 때문에 그렇게까지 신경쓸 정돈 아니고, 안정적이고 신뢰성 있는 출력형식을 만드는 데에 OutputParser가 훨씬 효과적임.
    - 자동화, 확장성 등이 좋음.
- Q12-2. 출력형식 만들 때 프롬프팅과 OutputParser를 같이 활용하는 방법은 어때?
    - 좋음. 프롬프팅으로 일차적으로 제어하고, 오류를 OutputParser로 처리한다든지 보완적으로 사용할 수 있음.



- Q13. 사용자가 입력한 쿼리를 runnablepassthrough가 별다른 변환 없이 바로 retriever로 전달한다며. 근데 retriever가 코사인 유사도를 계산하기 위해서는 쿼리도 임베딩 벡터로 변환해야 하는데 그건 누가 함?
    - as_retriever 하면 retriever가 알아서 해줌. 네가 알아서 벡터화해서 보내고 싶으면 그렇게 할 수도 있긴 함. 데이터에 대한 인간의 통제권이 늘어나는 거지.



- Q14. langchain 라이브러리가 너무 고수준화돼있어서 디버깅이나 로직 수정이 제한적이라는 말이 있던데(내가 25년 초에 써볼 때만 해도 꽤 불편하다고 느낌..), 실제 연구나 서비스 개발할 때도 langchain 활용하는 것이 표준으로 자리잡았는지?
  - ㅇㅇ. langraph도 있는데 langchain이 더 널리 쓰이고.. langchain 자체도 아직 초기지만 빠르게 발전하고 있음
